# Trading Platform â€“ Master Checklist

**Last Updated:** January 18, 2026
**Project Owner:** Thomas Rogers

This checklist is the single source of truth to keep the project organized, grounded, and moving forward without losing architectural discipline.

Status markers:
- â¬œ Not started
- ğŸŸ¡ In progress
- âœ… Complete

---

## ğŸ§± Current Baseline (Locked In)

These are assumptions going forward. If one of these changes, the checklist must be updated.

### Infrastructure
- âœ… Raspberry Pi 5 (16GB RAM) provisioned and stable
- âœ… Docker installed and working
- âœ… Docker Compose in use
- âœ… PostgreSQL 17 container running (`trading-db`)
- âœ… Redis 8 container running (`trading-realtime-data-shared`)
- âœ… Redpanda (Kafka-compatible) container running (`trading-redpanda`)
- âœ… Redpanda Console accessible (port 8080)

### Stock-Service (Go)
- âœ… Service exists and connects to PostgreSQL
- âœ… Database migrations written and applied (8 migrations)
- âœ… Models and repositories implemented
- âœ… Unit tests added to repositories
- âœ… REST API endpoints working (health, stocks CRUD)
- âœ… Kafka consumer for `trading.orders` topic
- âœ… Raw trades stored to `raw_trades` table
- âœ… Position aggregation logic (BUY creates/updates, SELL closes)
- âœ… Trade history archival on position close
- âœ… Docker image built for ARM64 and published to GHCR

### Robinhood-Sync (Python)
- âœ… Service created and running on Raspberry Pi
- âœ… Connects to Robinhood API (robin_stocks library)
- âœ… Detects filled orders
- âœ… Publishes `TRADE_DETECTED` events to `trading.orders` topic
- âœ… Redis deduplication (tracks synced order IDs)
- âœ… Market hours scheduling (4am-8pm ET, Mon-Fri)
- âœ… Continuous and single-run modes supported
- âœ… Historical sync capability (`--days N`)

---

## ğŸ§  Architectural Rules (Non-Negotiable)

Use this as a guardrail when making decisions.

- âœ… Services communicate via **Kafka (Redpanda)**, not direct DB calls
- âœ… PostgreSQL is the **source of truth**, not Redis
- âœ… Redis is for **hot / ephemeral data only** (deduplication, caching)
- âœ… Each service has **one primary responsibility**
- âœ… No service reaches into another service's database tables
- âœ… Events are immutable (no edits, only new facts)

---

## ğŸ§ª Environment & Observability

### Local Infrastructure
- âœ… Docker Compose file documents all running services
- âœ… Redpanda Console / UI accessible locally (port 8080)
- ğŸŸ¡ Logs for each service are easy to find and readable
- âœ… `.env` files exist and are gitignored

### Sanity Checks
- âœ… Can connect to PostgreSQL from host (port 5432)
- âœ… Can connect to Redis from host (port 6379)
- âœ… Can produce and consume events in Redpanda (verified with robinhood-sync â†’ stock-service)

---

## ğŸ“¦ Event Foundation (Critical Path)

### Kafka / Redpanda Setup
- âœ… Redpanda running in KRaft mode (no Zookeeper)
- âœ… Topics created:
  - âœ… `trading.orders` (trade events from Robinhood)
  - âœ… `stock-events` (stock CRUD events)
  - â¬œ `stock.quotes.realtime` (price updates)
  - â¬œ `stock.indicators` (calculated indicators)
  - â¬œ `trading.alerts` (fired alerts)
- ğŸŸ¡ Topic naming conventions documented
- ğŸŸ¡ Event schemas defined (versioned)

### Event Design
- âœ… `TradeEvent` schema defined and working:
  ```json
  {
    "event_type": "TRADE_DETECTED",
    "source": "robinhood",
    "timestamp": "ISO8601",
    "data": {
      "order_id", "symbol", "side", "quantity",
      "average_price", "total_notional", "fees",
      "state", "executed_at", "created_at"
    }
  }
  ```
- â¬œ `QuoteEvent` schema defined
- â¬œ `IndicatorEvent` schema defined
- â¬œ All events include: symbol, timestamp, source, schema_version

---

## ğŸ“ˆ Market Data Ingestion (Go â€“ Producer)

### market-data-ingestion Service
- â¬œ Service scaffolded
- â¬œ Fetch quotes from Finnhub API
- â¬œ Publish `QuoteEvent` to `stock.quotes.realtime`
- â¬œ Rate limiting enforced (Finnhub free tier: 60/min)
- â¬œ Retries and error handling implemented
- â¬œ Structured logging added
- â¬œ Unit tests for Kafka producer

### Validation
- â¬œ Events visible in Redpanda Console
- â¬œ Payload matches schema exactly

---

## ğŸ’¾ Stock Persistence Service (Consumer)

### Price Data Responsibilities
- â¬œ Consume `stock.quotes.realtime`
- â¬œ Write current price snapshot to PostgreSQL (`stocks` table)
- â¬œ Append daily OHLCV to `price_data_daily`
- â¬œ Cache current price in Redis with TTL

### Engineering
- â¬œ Idempotent writes (safe reprocessing)
- â¬œ Consumer group configured correctly
- â¬œ Graceful shutdown handling
- â¬œ Unit tests for persistence logic

---

## ğŸ“Š Analytics Service (High ROI)

### Real-Time Indicators
- â¬œ Consume `stock.quotes.realtime`
- â¬œ Calculate RSI, SMA, MACD, Bollinger Bands
- â¬œ Publish `IndicatorEvent` to `stock.indicators`
- â¬œ Persist indicators to `technical_indicators` table

### Quality Controls
- â¬œ Minimum data window checks
- â¬œ Timeframe clearly defined per indicator
- â¬œ No lookahead bias

---

## ğŸš¨ Alert Service

### Core Logic
- â¬œ Consume `stock.quotes.realtime`
- â¬œ Consume `stock.indicators`
- â¬œ Load `alert_rules` from PostgreSQL
- â¬œ Evaluate multi-condition rules
- â¬œ Enforce cooldowns

### Notifications
- â¬œ Telegram integration working
- â¬œ Message templates standardized
- â¬œ Alerts logged to `alert_history`

---

## ğŸ¤– Trade Automation & Journaling

### Robinhood Sync
- âœ… Poll Robinhood API (every 10 minutes during market hours)
- âœ… Detect filled orders
- âœ… Publish `TradeEvent` to `trading.orders`
- âœ… Deduplicate via Redis

### Stock-Service Trade Processing
- âœ… Consume `trading.orders`
- âœ… Insert raw trades into `raw_trades` table
- âœ… Deduplicate by (order_id, source)
- âœ… Aggregate into positions (weighted avg price)
- âœ… Close positions on SELL and move to `trades_history`

### Trade Journal Service
- â¬œ Consume `trading.orders` (separate service)
- â¬œ Send Telegram journal prompts
- â¬œ Capture replies and update trade records
- â¬œ Voice note support (Whisper transcription)

---

## ğŸ“Š Portfolio & Review

### Portfolio Tracker
- â¬œ FastAPI service scaffolded
- â¬œ Read-only endpoints from PostgreSQL
- â¬œ Live prices from Redis

### Performance Review
- â¬œ Win rate calculation
- â¬œ Avg win / avg loss
- â¬œ Holding time analysis
- â¬œ Alert effectiveness metrics

---

## ğŸ” Backtesting & Iteration

- â¬œ Event replay from Kafka topics
- â¬œ Strategy rules extracted into reusable logic
- â¬œ Backtest results stored and compared
- â¬œ Parameters tuned with data, not intuition

---

## ğŸ§  Discipline Layer (Trader Rules)

Before every trade, the system should capture:

- â¬œ Entry reason logged
- â¬œ Stop loss defined
- â¬œ Profit target defined
- â¬œ Risk % of account calculated
- â¬œ Strategy tag assigned

After every trade:

- â¬œ Exit reason logged
- â¬œ What went right
- â¬œ What went wrong
- â¬œ Trade graded (Aâ€“F)

---

## ğŸ Definition of Success

This project is succeeding if:
- ğŸŸ¡ Trades are explainable (raw trades captured, positions tracked)
- â¬œ Rules are followed more often than overridden
- â¬œ Alerts arrive before decisions are emotional
- â¬œ Journals are filled automatically
- â¬œ Strategy changes are data-backed

If a feature does not improve decision quality, it is optional.

---

## ğŸ“‹ Current Data Flow (Working)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Robinhood   â”‚
â”‚   Account    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Poll every 10 min (market hours)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ robinhood-sync (Python)  â”‚
â”‚ - Fetch filled orders    â”‚
â”‚ - Dedupe via Redis       â”‚
â”‚ - Publish to Kafka       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ TRADE_DETECTED event
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redpanda (Kafka)         â”‚
â”‚ Topic: trading.orders    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Consumer
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ stock-service (Go)       â”‚
â”‚ - Consume events         â”‚
â”‚ - Save to raw_trades     â”‚
â”‚ - Update positions       â”‚
â”‚ - Archive to history     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL               â”‚
â”‚ - raw_trades             â”‚
â”‚ - positions              â”‚
â”‚ - trades_history         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Next Milestones

### Milestone 1: Market Data Pipeline (NEXT)
Build the price data ingestion system:
1. â¬œ Create market-data-ingestion service (Go)
2. â¬œ Integrate Finnhub API
3. â¬œ Publish to `stock.quotes.realtime`
4. â¬œ Update stock-service to consume price events
5. â¬œ Populate `price_data_daily` table

### Milestone 2: Analytics & Indicators
Calculate technical indicators:
1. â¬œ Create analytics-service (Python)
2. â¬œ Calculate RSI, MACD, SMA, Bollinger Bands
3. â¬œ Publish to `stock.indicators`
4. â¬œ Persist to `technical_indicators` table

### Milestone 3: Alerts & Notifications
Never miss a setup:
1. â¬œ Create alert-service (Go)
2. â¬œ Telegram bot integration
3. â¬œ Multi-condition rule evaluation
4. â¬œ Cooldown management

### Milestone 4: Trade Journaling
Capture reasoning:
1. â¬œ Create trade-journal service (Python)
2. â¬œ Telegram prompts on new trades
3. â¬œ Reply capture and storage
4. â¬œ Voice note transcription

---

## ğŸ“ Session Log

### Session 1 (January 17, 2026)
- Built database schema and migrations
- Created Go market data service (database-centric)
- Set up Docker Compose
- Decided on event-driven architecture with Kafka

### Session 2 (January 17-18, 2026)
- Built robinhood-sync service (Python)
- Added Kafka consumer to stock-service
- Created raw_trades table and migration
- Verified end-to-end flow: Robinhood â†’ Kafka â†’ stock-service â†’ PostgreSQL
- Position aggregation and trade history working

---

**End of Checklist**
